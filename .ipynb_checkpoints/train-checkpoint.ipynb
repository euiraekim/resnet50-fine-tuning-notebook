{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d79be0e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\envs\\eui\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\anaconda3\\envs\\eui\\lib\\site-packages\\numpy\\.libs\\libopenblas.NOIJJG62EMASZI6NYURL6JBKM4EVBGM7.gfortran-win_amd64.dll\n",
      "C:\\anaconda3\\envs\\eui\\lib\\site-packages\\numpy\\.libs\\libopenblas.WCDJNK7YVMPZQ2ME2ZZHJJRJ3JIKNDB7.gfortran-win_amd64.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\\n%s\" %\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os, cv2, random\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6bffcd89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "      tf.config.experimental.set_virtual_device_configuration(\n",
    "          gpus[0],\n",
    "          [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=1024 * 6)])\n",
    "      logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "      print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "      print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d62274db",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "class_num = 3\n",
    "train_images_per_class = 400\n",
    "test_images_per_class = 100\n",
    "learning_rate = 0.00001\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "722525bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = os.path.join('images/', 'train/')\n",
    "validation_dir = os.path.join('images/', 'test/')\n",
    "\n",
    "train_X = []\n",
    "train_y = []\n",
    "val_X = []\n",
    "val_y = []\n",
    "\n",
    "for animal_name in os.listdir(train_dir):\n",
    "    image_list = os.listdir(os.path.join(train_dir, animal_name))\n",
    "#     image_list = random.sample(image_list, 150)\n",
    "    for image_name in image_list:\n",
    "        image = cv2.imread(os.path.join(train_dir, animal_name, image_name))\n",
    "        train_X.append(image)\n",
    "        train_y.append(int(animal_name))\n",
    "\n",
    "for animal_name in os.listdir(validation_dir):\n",
    "    image_list = os.listdir(os.path.join(validation_dir, animal_name))\n",
    "#     image_list = random.sample(image_list, 40)\n",
    "    for image_name in image_list:\n",
    "        image = cv2.imread(os.path.join(validation_dir, animal_name, image_name))\n",
    "        val_X.append(image)\n",
    "        val_y.append(int(animal_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a80b6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(image, label):\n",
    "    final_image = tf.keras.applications.resnet50.preprocess_input(image)\n",
    "    return final_image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a223e77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_X, train_y)).map(preprocess).shuffle(class_num*train_images_per_class).batch(batch_size)\n",
    "validation_dataset = tf.data.Dataset.from_tensor_slices((val_X, val_y)).map(preprocess).shuffle(class_num*test_images_per_class).batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9b23013a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d37266c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = tf.keras.applications.resnet50.ResNet50(weights='imagenet', include_top=False)\n",
    "headModel = tf.keras.layers.GlobalAveragePooling2D()(base_model.output)\n",
    "headModel = tf.keras.layers.Flatten(name=\"flatten\")(headModel)\n",
    "headModel = tf.keras.layers.Dense(256, activation=\"relu\")(headModel)\n",
    "headModel = tf.keras.layers.Dropout(0.5)(headModel)\n",
    "output = tf.keras.layers.Dense(class_num, activation='softmax')(headModel)\n",
    "model = tf.keras.Model(inputs=base_model.input, outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7041f67a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, None, None,  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, None, None, 3 0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_conv (Conv2D)             (None, None, None, 6 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1_bn (BatchNormalization)   (None, None, None, 6 256         conv1_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1_relu (Activation)         (None, None, None, 6 0           conv1_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, None, None, 6 0           conv1_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pool (MaxPooling2D)       (None, None, None, 6 0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, None, None, 6 4160        pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, None, None, 6 256         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, None, None, 6 0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, None, None, 6 36928       conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_bn (BatchNormali (None, None, None, 6 256         conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_relu (Activation (None, None, None, 6 0           conv2_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_conv (Conv2D)    (None, None, None, 2 16640       pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_conv (Conv2D)    (None, None, None, 2 16640       conv2_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_bn (BatchNormali (None, None, None, 2 1024        conv2_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_bn (BatchNormali (None, None, None, 2 1024        conv2_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_add (Add)          (None, None, None, 2 0           conv2_block1_0_bn[0][0]          \n",
      "                                                                 conv2_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_out (Activation)   (None, None, None, 2 0           conv2_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, None, None, 6 16448       conv2_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, None, None, 6 256         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, None, None, 6 0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, None, None, 6 36928       conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_bn (BatchNormali (None, None, None, 6 256         conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_relu (Activation (None, None, None, 6 0           conv2_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_conv (Conv2D)    (None, None, None, 2 16640       conv2_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_bn (BatchNormali (None, None, None, 2 1024        conv2_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_add (Add)          (None, None, None, 2 0           conv2_block1_out[0][0]           \n",
      "                                                                 conv2_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_out (Activation)   (None, None, None, 2 0           conv2_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, None, None, 6 16448       conv2_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, None, None, 6 256         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, None, None, 6 0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, None, None, 6 36928       conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_bn (BatchNormali (None, None, None, 6 256         conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_relu (Activation (None, None, None, 6 0           conv2_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_conv (Conv2D)    (None, None, None, 2 16640       conv2_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_bn (BatchNormali (None, None, None, 2 1024        conv2_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_add (Add)          (None, None, None, 2 0           conv2_block2_out[0][0]           \n",
      "                                                                 conv2_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_out (Activation)   (None, None, None, 2 0           conv2_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, None, None, 1 32896       conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, None, None, 1 512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, None, None, 1 0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, None, None, 1 147584      conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_bn (BatchNormali (None, None, None, 1 512         conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_relu (Activation (None, None, None, 1 0           conv3_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_conv (Conv2D)    (None, None, None, 5 131584      conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_conv (Conv2D)    (None, None, None, 5 66048       conv3_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_bn (BatchNormali (None, None, None, 5 2048        conv3_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_bn (BatchNormali (None, None, None, 5 2048        conv3_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_add (Add)          (None, None, None, 5 0           conv3_block1_0_bn[0][0]          \n",
      "                                                                 conv3_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_out (Activation)   (None, None, None, 5 0           conv3_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, None, None, 1 65664       conv3_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, None, None, 1 512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, None, None, 1 0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, None, None, 1 147584      conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_bn (BatchNormali (None, None, None, 1 512         conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_relu (Activation (None, None, None, 1 0           conv3_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_conv (Conv2D)    (None, None, None, 5 66048       conv3_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_bn (BatchNormali (None, None, None, 5 2048        conv3_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_add (Add)          (None, None, None, 5 0           conv3_block1_out[0][0]           \n",
      "                                                                 conv3_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_out (Activation)   (None, None, None, 5 0           conv3_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, None, None, 1 65664       conv3_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, None, None, 1 512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, None, None, 1 0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, None, None, 1 147584      conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_bn (BatchNormali (None, None, None, 1 512         conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_relu (Activation (None, None, None, 1 0           conv3_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_conv (Conv2D)    (None, None, None, 5 66048       conv3_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_bn (BatchNormali (None, None, None, 5 2048        conv3_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_add (Add)          (None, None, None, 5 0           conv3_block2_out[0][0]           \n",
      "                                                                 conv3_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_out (Activation)   (None, None, None, 5 0           conv3_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, None, None, 1 65664       conv3_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, None, None, 1 512         conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, None, None, 1 0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, None, None, 1 147584      conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_bn (BatchNormali (None, None, None, 1 512         conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_relu (Activation (None, None, None, 1 0           conv3_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_conv (Conv2D)    (None, None, None, 5 66048       conv3_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_bn (BatchNormali (None, None, None, 5 2048        conv3_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_add (Add)          (None, None, None, 5 0           conv3_block3_out[0][0]           \n",
      "                                                                 conv3_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_out (Activation)   (None, None, None, 5 0           conv3_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, None, None, 2 131328      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, None, None, 2 1024        conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, None, None, 2 0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, None, None, 2 590080      conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_bn (BatchNormali (None, None, None, 2 1024        conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_relu (Activation (None, None, None, 2 0           conv4_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_conv (Conv2D)    (None, None, None, 1 525312      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_conv (Conv2D)    (None, None, None, 1 263168      conv4_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_bn (BatchNormali (None, None, None, 1 4096        conv4_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_bn (BatchNormali (None, None, None, 1 4096        conv4_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_add (Add)          (None, None, None, 1 0           conv4_block1_0_bn[0][0]          \n",
      "                                                                 conv4_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_out (Activation)   (None, None, None, 1 0           conv4_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, None, None, 2 262400      conv4_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, None, None, 2 1024        conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, None, None, 2 0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, None, None, 2 590080      conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_bn (BatchNormali (None, None, None, 2 1024        conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_relu (Activation (None, None, None, 2 0           conv4_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_conv (Conv2D)    (None, None, None, 1 263168      conv4_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_bn (BatchNormali (None, None, None, 1 4096        conv4_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_add (Add)          (None, None, None, 1 0           conv4_block1_out[0][0]           \n",
      "                                                                 conv4_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_out (Activation)   (None, None, None, 1 0           conv4_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, None, None, 2 262400      conv4_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, None, None, 2 1024        conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, None, None, 2 0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, None, None, 2 590080      conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_bn (BatchNormali (None, None, None, 2 1024        conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_relu (Activation (None, None, None, 2 0           conv4_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_conv (Conv2D)    (None, None, None, 1 263168      conv4_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_bn (BatchNormali (None, None, None, 1 4096        conv4_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_add (Add)          (None, None, None, 1 0           conv4_block2_out[0][0]           \n",
      "                                                                 conv4_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_out (Activation)   (None, None, None, 1 0           conv4_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, None, None, 2 262400      conv4_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, None, None, 2 1024        conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, None, None, 2 0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, None, None, 2 590080      conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_bn (BatchNormali (None, None, None, 2 1024        conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_relu (Activation (None, None, None, 2 0           conv4_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_conv (Conv2D)    (None, None, None, 1 263168      conv4_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_bn (BatchNormali (None, None, None, 1 4096        conv4_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_add (Add)          (None, None, None, 1 0           conv4_block3_out[0][0]           \n",
      "                                                                 conv4_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_out (Activation)   (None, None, None, 1 0           conv4_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, None, None, 2 262400      conv4_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, None, None, 2 1024        conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, None, None, 2 0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, None, None, 2 590080      conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_bn (BatchNormali (None, None, None, 2 1024        conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_relu (Activation (None, None, None, 2 0           conv4_block5_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_conv (Conv2D)    (None, None, None, 1 263168      conv4_block5_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_bn (BatchNormali (None, None, None, 1 4096        conv4_block5_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_add (Add)          (None, None, None, 1 0           conv4_block4_out[0][0]           \n",
      "                                                                 conv4_block5_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_out (Activation)   (None, None, None, 1 0           conv4_block5_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, None, None, 2 262400      conv4_block5_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, None, None, 2 1024        conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, None, None, 2 0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, None, None, 2 590080      conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_bn (BatchNormali (None, None, None, 2 1024        conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_relu (Activation (None, None, None, 2 0           conv4_block6_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_conv (Conv2D)    (None, None, None, 1 263168      conv4_block6_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_bn (BatchNormali (None, None, None, 1 4096        conv4_block6_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_add (Add)          (None, None, None, 1 0           conv4_block5_out[0][0]           \n",
      "                                                                 conv4_block6_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_out (Activation)   (None, None, None, 1 0           conv4_block6_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, None, None, 5 524800      conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, None, None, 5 2048        conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation (None, None, None, 5 0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)    (None, None, None, 5 2359808     conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_bn (BatchNormali (None, None, None, 5 2048        conv5_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_relu (Activation (None, None, None, 5 0           conv5_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_conv (Conv2D)    (None, None, None, 2 2099200     conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_conv (Conv2D)    (None, None, None, 2 1050624     conv5_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_bn (BatchNormali (None, None, None, 2 8192        conv5_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_bn (BatchNormali (None, None, None, 2 8192        conv5_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_add (Add)          (None, None, None, 2 0           conv5_block1_0_bn[0][0]          \n",
      "                                                                 conv5_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_out (Activation)   (None, None, None, 2 0           conv5_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, None, None, 5 1049088     conv5_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, None, None, 5 2048        conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation (None, None, None, 5 0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)    (None, None, None, 5 2359808     conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_bn (BatchNormali (None, None, None, 5 2048        conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_relu (Activation (None, None, None, 5 0           conv5_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_conv (Conv2D)    (None, None, None, 2 1050624     conv5_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_bn (BatchNormali (None, None, None, 2 8192        conv5_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_add (Add)          (None, None, None, 2 0           conv5_block1_out[0][0]           \n",
      "                                                                 conv5_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_out (Activation)   (None, None, None, 2 0           conv5_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)    (None, None, None, 5 1049088     conv5_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormali (None, None, None, 5 2048        conv5_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation (None, None, None, 5 0           conv5_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)    (None, None, None, 5 2359808     conv5_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_bn (BatchNormali (None, None, None, 5 2048        conv5_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_relu (Activation (None, None, None, 5 0           conv5_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_conv (Conv2D)    (None, None, None, 2 1050624     conv5_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_bn (BatchNormali (None, None, None, 2 8192        conv5_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_add (Add)          (None, None, None, 2 0           conv5_block2_out[0][0]           \n",
      "                                                                 conv5_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_out (Activation)   (None, None, None, 2 0           conv5_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d (Globa (None, 2048)         0           conv5_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 2048)         0           global_average_pooling2d[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 256)          524544      flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 256)          0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 3)            771         dropout[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 24,113,027\n",
      "Trainable params: 24,059,907\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c252ddb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# flag = False\n",
    "# for layer in base_model.layers:\n",
    "#     if layer.name == 'conv5_block1_1_conv':\n",
    "#         flag = True\n",
    "#     print(layer.trainable)\n",
    "#     if not flag:\n",
    "#         layer.trainable = False\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.training = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d589031c",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=opt, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "31648e13",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "150/150 [==============================] - 22s 82ms/step - loss: 1.1911 - accuracy: 0.4479 - val_loss: 0.6126 - val_accuracy: 0.7800oss: 1.3260 - accu - ETA: 6s - loss: 1.3203 - ac - ETA: 6s - loss: 1.3104 - accuracy: 0. - ETA: 6s - los - ETA: 5s - loss: 1.2905 -  - ETA: 3s - loss: 1.2559 - accuracy: 0.42 - ETA: 3s - loss: 1.2547 - accuracy: 0.42 - ETA: 3s - loss: 1.2534 - accu - ETA: 3s - loss: 1.2466 - accuracy - ETA: 1s - loss: 1.2174 - accuracy: 0.43 - ETA: 1s - loss: 1.2163 - ac - ETA:  - ETA: 0s - loss: 1.1920 - accuracy: 0.44\n",
      "Epoch 2/100\n",
      "150/150 [==============================] - 13s 69ms/step - loss: 0.6354 - accuracy: 0.7335 - val_loss: 0.3789 - val_accuracy: 0.86333s - loss: 0.656 - ETA: 2s - - ETA: 1s - loss: 0.6464 - accuracy: 0. - ETA:  - ETA: 0s - loss: 0.6386 - accu - ETA: 0s - loss: 0.6365 - accuracy: \n",
      "Epoch 3/100\n",
      "150/150 [==============================] - 13s 69ms/step - loss: 0.3535 - accuracy: 0.8849 - val_loss: 0.2833 - val_accuracy: 0.9067 - ETA - E\n",
      "Epoch 4/100\n",
      "150/150 [==============================] - 13s 69ms/step - loss: 0.2570 - accuracy: 0.9159 - val_loss: 0.2366 - val_accuracy: 0.9167s: 0.2908 - accuracy: 0.89 - ETA: 6s - loss: 0.2905 -  - ETA: 0s - loss: 0.259\n",
      "Epoch 5/100\n",
      "150/150 [==============================] - 13s 69ms/step - loss: 0.1728 - accuracy: 0.9448 - val_loss: 0.2046 - val_accuracy: 0.9233 - loss: 0.1735 - accuracy: 0.94 - ETA: 4s - ETA: 3s - loss: 0.1735 - accuracy: 0.94 - ETA: 3s - loss: 0.173 - ETA: 2s - loss: 0.1726 -  - E\n",
      "Epoch 6/100\n",
      "150/150 [==============================] - 13s 70ms/step - loss: 0.1269 - accuracy: 0.9650 - val_loss: 0.1945 - val_accuracy: 0.9333TA: 1s - loss: 0.1301 - accuracy: 0.96 - ETA: 1s - loss: 0.1299 - accu\n",
      "Epoch 7/100\n",
      "150/150 [==============================] - 13s 70ms/step - loss: 0.0687 - accuracy: 0.9863 - val_loss: 0.1781 - val_accuracy: 0.94006 - accuracy - ETA: 4s - loss: 0.0650 - accura - ETA: 3s - loss: 0.0656 -  - ETA: 3s - loss: 0.0664 - accuracy: 0. - ETA: 3s - loss: 0.0665 - accuracy - ETA: 2s - ETA: 1s - loss: 0.0 - E\n",
      "Epoch 8/100\n",
      "150/150 [==============================] - 13s 69ms/step - loss: 0.0634 - accuracy: 0.9886 - val_loss: 0.1631 - val_accuracy: 0.9400 loss: 0.0630 - accuracy:  - ETA: 1s - loss: 0.0631 - accu - ETA: 0s - loss: 0.063 - ETA: 0s - loss: 0.0634 - accuracy: 0.\n",
      "Epoch 9/100\n",
      "150/150 [==============================] - 13s 69ms/step - loss: 0.0457 - accuracy: 0.9942 - val_loss: 0.1525 - val_accuracy: 0.9600 ETA: 3s - los - ETA: 1s - loss: 0.0442 - accuracy: 0. - ETA: 1s - loss: 0.0444 - accu - ETA: 1s - loss: 0.0 - ETA: 0s - loss: 0\n",
      "Epoch 10/100\n",
      "150/150 [==============================] - 13s 69ms/step - loss: 0.0362 - accuracy: 0.9970 - val_loss: 0.1551 - val_accuracy: 0.95670s - los\n",
      "Epoch 11/100\n",
      "150/150 [==============================] - 13s 70ms/step - loss: 0.0325 - accuracy: 0.9946 - val_loss: 0.1614 - val_accuracy: 0.95335s - l - ETA: 4s - ETA: 3s - loss: 0.0289 - accuracy: 0. - ETA: 3s - loss: 0.0290 - accuracy:  - ETA: 3s - - ETA\n",
      "Epoch 12/100\n",
      "150/150 [==============================] - 13s 69ms/step - loss: 0.0553 - accuracy: 0.9891 - val_loss: 0.1644 - val_accuracy: 0.9567\n",
      "Epoch 13/100\n",
      "150/150 [==============================] - 13s 69ms/step - loss: 0.0313 - accuracy: 0.9928 - val_loss: 0.1582 - val_accuracy: 0.95004s - loss: 0.0358 - accura - ETA: 4s - loss: 0.0355 - accuracy: 0. - ETA: 4s - loss: 0.0354 - accuracy: 0.99 - ETA: 4s - loss: 0.0353 - accu - ETA: 2s - loss: 0.0334 - accuracy - ETA: 2s - loss: 0.0332 - accu - ETA: 2s - loss: 0.0328 - accuracy: 0. - ETA: 1s - loss: - E\n",
      "Epoch 14/100\n",
      "150/150 [==============================] - 13s 69ms/step - loss: 0.0286 - accuracy: 0.9954 - val_loss: 0.1556 - val_accuracy: 0.9567.0336 - accuracy: 0. - ETA: 7s - loss: 0 - ETA: 6s - loss: 0.0321 - accuracy:  - ETA: 6s - loss: 0.0317 - accura - ETA: 5s - loss: 0.0310 - accuracy:  - ETA: 5s - loss: 0.0307 - ac - ETA: 5s - loss: 0.0301 - ac - ETA: 3s - loss: 0.0296 - accuracy: 0.99 - ETA: 3s - loss: 0.0296 - accuracy - ETA: 3s - loss: 0.0294 - accuracy:  - ETA: 3s - loss: 0 - ETA: 2s - loss: 0.0291 - ac - ETA: 1s - loss: 0\n",
      "Epoch 15/100\n",
      "150/150 [==============================] - 13s 69ms/step - loss: 0.0179 - accuracy: 0.9953 - val_loss: 0.1568 - val_accuracy: 0.9533s: 0.013 - ETA: 7s - los - ETA: 6s - loss: 0.0161  - ETA: 4s - ETA: 3s - loss: 0.0180 - accura - ETA: 3s - loss: 0.0180 -  - ETA: 3s - loss: 0.0180 - accuracy:  - ETA:  - ETA: 0s - loss: 0.0179 - \n",
      "Epoch 16/100\n",
      "150/150 [==============================] - 13s 69ms/step - loss: 0.0185 - accuracy: 0.9965 - val_loss: 0.1723 - val_accuracy: 0.95338s - loss: 0.0163 - accuracy: 1.00 - ETA: 8s - loss: - ETA: 7s - - ETA - ETA: 3s - loss: 0.0173 - accuracy - ETA: 1s - loss: 0.0182 - accuracy\n",
      "Epoch 17/100\n",
      "150/150 [==============================] - 13s 69ms/step - loss: 0.0252 - accuracy: 0.9897 - val_loss: 0.1524 - val_accuracy: 0.95678s - loss: 0.0354 -  - - ETA: 6s - loss: 0.0262 - accuracy: 0.98 - ETA: 6s - loss: 0.0260 - accu - ETA: 5s - - ETA: 4s - loss: 0.0246 - accuracy:  - ETA: 1s - loss: 0\n",
      "Epoch 18/100\n",
      "150/150 [==============================] - 13s 69ms/step - loss: 0.0166 - accuracy: 0.9955 - val_loss: 0.1457 - val_accuracy: 0.95675s - loss: 0.0151 - accura - ETA: 5s - l - ETA: 4s - loss: 0.0 - ETA: 2s - loss: 0.0164 - accu - ETA: 1s - loss: 0.0165 - accu - ETA: 1s - loss: 0.0165 - ac - ETA\n",
      "Epoch 19/100\n",
      "150/150 [==============================] - 13s 69ms/step - loss: 0.0139 - accuracy: 0.9983 - val_loss: 0.1467 - val_accuracy: 0.96007s - loss: 0.0079 - accuracy: 1. - ETA: 7s -\n",
      "Epoch 20/100\n",
      "150/150 [==============================] - 13s 69ms/step - loss: 0.0147 - accuracy: 0.9945 - val_loss: 0.1620 - val_accuracy: 0.9500\n",
      "Epoch 21/100\n",
      "150/150 [==============================] - 13s 69ms/step - loss: 0.0130 - accuracy: 0.9958 - val_loss: 0.1611 - val_accuracy: 0.9500\n",
      "Epoch 22/100\n",
      "150/150 [==============================] - 13s 69ms/step - loss: 0.0111 - accuracy: 0.9973 - val_loss: 0.1424 - val_accuracy: 0.9600\n",
      "Epoch 23/100\n",
      "150/150 [==============================] - 13s 69ms/step - loss: 0.0169 - accuracy: 0.9950 - val_loss: 0.1646 - val_accuracy: 0.9567\n",
      "Epoch 24/100\n",
      "150/150 [==============================] - 13s 69ms/step - loss: 0.0116 - accuracy: 0.9980 - val_loss: 0.1793 - val_accuracy: 0.9400\n",
      "Epoch 25/100\n",
      "150/150 [==============================] - 13s 69ms/step - loss: 0.0275 - accuracy: 0.9925 - val_loss: 0.1536 - val_accuracy: 0.9633\n",
      "Epoch 26/100\n",
      "150/150 [==============================] - 13s 69ms/step - loss: 0.0094 - accuracy: 0.9976 - val_loss: 0.1772 - val_accuracy: 0.9600\n",
      "Epoch 27/100\n",
      "150/150 [==============================] - 13s 69ms/step - loss: 0.0104 - accuracy: 0.9990 - val_loss: 0.1662 - val_accuracy: 0.9600\n",
      "Epoch 28/100\n",
      "150/150 [==============================] - 13s 69ms/step - loss: 0.0103 - accuracy: 0.9978 - val_loss: 0.1863 - val_accuracy: 0.9500\n",
      "Epoch 29/100\n",
      "150/150 [==============================] - 13s 69ms/step - loss: 0.0050 - accuracy: 0.9998 - val_loss: 0.1704 - val_accuracy: 0.9567\n",
      "Epoch 30/100\n",
      "150/150 [==============================] - 13s 69ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.1691 - val_accuracy: 0.9500\n",
      "Epoch 31/100\n",
      "150/150 [==============================] - 13s 69ms/step - loss: 0.0037 - accuracy: 0.9999 - val_loss: 0.1730 - val_accuracy: 0.9600\n",
      "Epoch 32/100\n",
      "150/150 [==============================] - 13s 69ms/step - loss: 0.0205 - accuracy: 0.9954 - val_loss: 0.2079 - val_accuracy: 0.9533 loss: 0.0211 - accura - ETA: 0s - los\n",
      "Epoch 33/100\n",
      "150/150 [==============================] - 13s 69ms/step - loss: 0.0049 - accuracy: 0.9993 - val_loss: 0.1710 - val_accuracy: 0.9567\n",
      "Epoch 34/100\n",
      "150/150 [==============================] - 13s 69ms/step - loss: 0.0171 - accuracy: 0.9960 - val_loss: 0.2105 - val_accuracy: 0.9400\n",
      "Epoch 35/100\n",
      "150/150 [==============================] - 13s 69ms/step - loss: 0.0083 - accuracy: 0.9977 - val_loss: 0.1592 - val_accuracy: 0.9533\n",
      "Epoch 36/100\n",
      "150/150 [==============================] - 13s 69ms/step - loss: 0.0039 - accuracy: 0.9998 - val_loss: 0.1615 - val_accuracy: 0.9600\n",
      "Epoch 37/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150/150 [==============================] - 13s 69ms/step - loss: 0.0075 - accuracy: 0.9979 - val_loss: 0.1600 - val_accuracy: 0.9600\n",
      "Epoch 38/100\n",
      "150/150 [==============================] - 13s 69ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.1559 - val_accuracy: 0.9600TA: 5s - loss: 0.0063 - accuracy - ETA: 4s - loss: 0.0053 - accuracy\n",
      "Epoch 39/100\n",
      "150/150 [==============================] - 13s 69ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.1594 - val_accuracy: 0.9667 0.0020 - accura\n",
      "Epoch 40/100\n",
      "150/150 [==============================] - 13s 69ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.1663 - val_accuracy: 0.9667\n",
      "Epoch 41/100\n",
      "150/150 [==============================] - 13s 69ms/step - loss: 0.0044 - accuracy: 0.9987 - val_loss: 0.1758 - val_accuracy: 0.9567\n",
      "Epoch 42/100\n",
      "150/150 [==============================] - 13s 69ms/step - loss: 0.0159 - accuracy: 0.9957 - val_loss: 0.2186 - val_accuracy: 0.9500\n",
      "Epoch 43/100\n",
      "150/150 [==============================] - 13s 69ms/step - loss: 0.0145 - accuracy: 0.9960 - val_loss: 0.1846 - val_accuracy: 0.9567\n",
      "Epoch 44/100\n",
      "150/150 [==============================] - 13s 69ms/step - loss: 0.0031 - accuracy: 0.9998 - val_loss: 0.2237 - val_accuracy: 0.9433\n",
      "Epoch 45/100\n",
      "150/150 [==============================] - 13s 69ms/step - loss: 0.0150 - accuracy: 0.9927 - val_loss: 0.1981 - val_accuracy: 0.9600 - loss: - ETA: 3s - loss: 0 - ETA: 1s - loss: 0.0159 - accu - ETA: 0s -\n",
      "Epoch 46/100\n",
      "150/150 [==============================] - 13s 69ms/step - loss: 0.0057 - accuracy: 0.9971 - val_loss: 0.2069 - val_accuracy: 0.9667 - los - ETA: 6s - loss: 0.0058 - accura - ETA: 5s - loss: 0.0057 - ac - ETA: 5s - l - ETA: 4s - loss: 0 - ETA: 3s - loss: 0.0049 - accu - ETA: 3s - loss: 0.0051 - accuracy: 0.99 - ETA: 3s - loss: 0.0051 - ac - ETA: 2s - loss: 0.0053 - accuracy - ETA: 2s - loss: 0.0053 -  - ETA:  - ETA: \n",
      "Epoch 47/100\n",
      "150/150 [==============================] - 13s 69ms/step - loss: 0.0041 - accuracy: 0.9996 - val_loss: 0.1740 - val_accuracy: 0.9600cu - ETA: 0s - loss: 0.0040 \n",
      "Epoch 48/100\n",
      "150/150 [==============================] - 13s 69ms/step - loss: 0.0080 - accuracy: 0.9993 - val_loss: 0.1883 - val_accuracy: 0.9533: 6s - - E - ETA: 0s - loss: 0.0\n",
      "Epoch 49/100\n",
      "150/150 [==============================] - 13s 69ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.1899 - val_accuracy: 0.9567oss:\n",
      "Epoch 50/100\n",
      "150/150 [==============================] - 13s 69ms/step - loss: 0.0034 - accuracy: 0.9983 - val_loss: 0.2160 - val_accuracy: 0.9600\n",
      "Epoch 51/100\n",
      "150/150 [==============================] - 13s 69ms/step - loss: 0.0035 - accuracy: 0.9992 - val_loss: 0.2175 - val_accuracy: 0.9467 loss: 0.0022 - accu - ETA: 4s - loss: 0.0022 - accuracy - - ETA: 0s - loss: 0.0033 - \n",
      "Epoch 52/100\n",
      "150/150 [==============================] - 13s 69ms/step - loss: 0.0067 - accuracy: 0.9982 - val_loss: 0.1994 - val_accuracy: 0.9567.0071 - accura - ETA: 1s - loss: 0.0071 - accura\n",
      "Epoch 53/100\n",
      "150/150 [==============================] - 13s 69ms/step - loss: 0.0096 - accuracy: 0.9960 - val_loss: 0.1960 - val_accuracy: 0.9567s: 0.0098 - accuracy: 0. - ETA: 4s - los - ETA: 3s - loss: 0.0097 - ac - ETA: 3s - loss: 0.0097 - accuracy: 0. - ETA: 3s - loss: 0.0097 - accuracy - ETA: 2s - loss: 0.0097 - accuracy:  - ETA: 2s - ETA: 0s - loss: 0.0096 - accuracy: 0.99 - ETA: 0s - loss: 0.0096 - accuracy: 0. - ETA: 0s - loss: 0.0096 - accuracy: \n",
      "Epoch 54/100\n",
      "150/150 [==============================] - 13s 69ms/step - loss: 0.0046 - accuracy: 0.9952 - val_loss: 0.1848 - val_accuracy: 0.9600 - ETA: 6s - loss: 0.011 - ETA: 6s - loss: 0.0095 - accuracy: 0. - ETA: 5s - loss: 0.0\n",
      "Epoch 55/100\n",
      "150/150 [==============================] - 13s 69ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.1933 - val_accuracy: 0.9600 - ETA: 4s - loss: 8.2615e-04 - accu - ETA: 3s - loss: 8.4823e-04  - ETA: 3s - loss: 8.7520e-04 - accura - ETA: 3s - loss: - ETA: 2s - loss: 9\n",
      "Epoch 56/100\n",
      "150/150 [==============================] - 13s 69ms/step - loss: 0.0044 - accuracy: 0.9980 - val_loss: 0.1726 - val_accuracy: 0.9500curacy: 0.99 - ETA: 0s -\n",
      "Epoch 57/100\n",
      "150/150 [==============================] - 13s 69ms/step - loss: 0.0055 - accuracy: 0.9982 - val_loss: 0.2169 - val_accuracy: 0.95336s - loss: 0.0037 - ac - ETA: 5s - loss: 0.0037 - accuracy: 1.00 - ETA: 5s - los - ETA: 3s - loss: 0.0042 - accuracy: 0. - ETA: 3s - loss: 0.0043 - accu - - ETA: 1s - loss: 0.0050 - accura - ETA: 1s - loss: - ETA: 0s - loss: 0.0053 - accu - ETA: 0s - loss: 0.0054 - accuracy: 0.99 - ETA: 0s - loss: 0.0054 - accura\n",
      "Epoch 58/100\n",
      "150/150 [==============================] - 13s 69ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2079 - val_accuracy: 0.95677s - loss: 3.9038e-0 - ETA: 5s - loss: 7.2360e-04 -  - ETA: 4s - loss: 7.6003e-04 \n",
      "Epoch 59/100\n",
      "150/150 [==============================] - 13s 69ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.2220 - val_accuracy: 0.9567\n",
      "Epoch 60/100\n",
      "150/150 [==============================] - 13s 69ms/step - loss: 7.1173e-04 - accuracy: 1.0000 - val_loss: 0.2180 - val_accuracy: 0.95334 - accu - ETA: 6s - loss: 5 - ETA: 5s - loss: 5.6686e - ETA: 4s - loss: 5.8873e-04  - ETA: 4s - loss: 6.2095e-04 - ac - ETA: 3s -\n",
      "Epoch 61/100\n",
      "150/150 [==============================] - 13s 69ms/step - loss: 9.8556e-04 - accuracy: 1.0000 - val_loss: 0.2238 - val_accuracy: 0.9567 9.9313e-04 - accura - ETA: 0s - l\n",
      "Epoch 62/100\n",
      "150/150 [==============================] - 13s 69ms/step - loss: 0.0054 - accuracy: 0.9975 - val_loss: 0.2034 - val_accuracy: 0.9600017 - accuracy: 0.99 - ETA: 7s - loss: - ETA: 6s - loss: 0.0034 - accuracy:  - ETA: 6s - loss: 0 - ETA - ETA: 3s - loss: 0.0053 - accura - ETA: 3s - loss: 0.005 - ETA\n",
      "Epoch 63/100\n",
      "150/150 [==============================] - 13s 69ms/step - loss: 0.0052 - accuracy: 0.9983 - val_loss: 0.2304 - val_accuracy: 0.9600cu - ETA: 4s - - ETA: 3s - loss: 0.0043 - accu - ETA: 3s - loss: 0.0045  - ETA: 2s - loss: 0.0 - ETA: 2s - loss: 0.0049 -  - ETA: 1s - l - ETA: 0s - l\n",
      "Epoch 64/100\n",
      "150/150 [==============================] - 13s 69ms/step - loss: 0.0032 - accuracy: 0.9977 - val_loss: 0.2014 - val_accuracy: 0.96003s - loss: 0.0041  - ETA: 3s - loss: 0.0039 - ac - ETA: 3s - loss: - ETA: 2s - los - ETA: 1s - loss: 0.0035  - ETA: 0s - los - ETA: 0s - loss: 0.0032 - accuracy: 0.99\n",
      "Epoch 65/100\n",
      "150/150 [==============================] - 13s 69ms/step - loss: 0.0067 - accuracy: 0.9971 - val_loss: 0.1993 - val_accuracy: 0.9600\n",
      "Epoch 66/100\n",
      "150/150 [==============================] - 13s 69ms/step - loss: 9.6492e-04 - accuracy: 1.0000 - val_loss: 0.2096 - val_accuracy: 0.95335s - loss: 6.8752e - ETA: 3s - loss: 7.7913e-0\n",
      "Epoch 67/100\n",
      "150/150 [==============================] - 13s 69ms/step - loss: 5.1871e-04 - accuracy: 1.0000 - val_loss: 0.2083 - val_accuracy: 0.9533oss: 1.946 - ETA: 7s - loss: 2.1677e-04 - accuracy: 1.00 - ETA: 7s - loss: 2.1892e-04 - accuracy: 1. - ETA: 7s - loss: 2.2197e-04 - accuracy: 1.00 - ETA: 7s - loss: 2.2328e-04 - accura - ETA: 6s - loss: 2.2953e-04 - accuracy: 1.00 - ETA: 6s - loss: 2.3109e-04 - accuracy: 1.00 - ETA: 6s - loss: 2.3243e-04 - accu - ETA: 6s - loss: 2.4667e-04 - accu - ETA: 6s - loss: 2.7193e-04  - ETA: 5s - loss: 3.0518e-04 - accu - ETA: 5s - loss: 3.1835e-0 - ETA: 4s - loss: 3.3861e - ETA: 3s - loss: - ETA: 2s - loss: 4.0305e-04 - accuracy: 1.00 - ETA: 2s - loss: 4.050 - ETA: 2s - loss: 4.2811e-04 - accuracy: 1. - ETA: 2s - loss: 4.3 - ETA: 1s - loss: 4.6197e-04 - ac - ETA: 0s - loss:\n",
      "Epoch 68/100\n",
      "150/150 [==============================] - 13s 69ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2091 - val_accuracy: 0.9533s: 2.5201e-04 - ac - ETA - ETA: 1s - loss: 9.8206e-04 -  - ETA: 1s - loss: 0.0010 - accu - ETA\n",
      "Epoch 69/100\n",
      "150/150 [==============================] - 13s 69ms/step - loss: 0.0018 - accuracy: 0.9984 - val_loss: 0.2274 - val_accuracy: 0.9567: 6s - loss: 0 - ETA: 0s - loss: 0.0018 - accuracy: \n",
      "Epoch 70/100\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-8fe5a262abd3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_dataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1098\u001b[0m                 _r=1):\n\u001b[0;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1100\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1101\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 828\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"xla\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    853\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    854\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 855\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    856\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    857\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2940\u001b[0m       (graph_function,\n\u001b[0;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2942\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   2944\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1916\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1917\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1918\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1919\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    553\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    554\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 555\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    556\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    557\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(train_dataset, epochs=epochs, validation_data=validation_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5975bec3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e681328e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "457337a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
